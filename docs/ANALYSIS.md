# Print Analysis (LLM-Powered)

Analyze your print sessions using AI to get tuning suggestions for Adaptive Flow parameters.

## Quick Start

```bash
cd ~/Klipper-Adaptive-Flow
python3 analyze_print.py --provider github   # Uses GitHub Models (free)
```

---

## Supported LLM Providers

| Provider | Cost | API Key Environment Variable |
|----------|------|------------------------------|
| **GitHub Models** | Free | `GITHUB_TOKEN` |
| **Ollama** | Free (local) | None required |
| **OpenAI** | Paid | `OPENAI_API_KEY` |
| **Anthropic** | Paid | `ANTHROPIC_API_KEY` |
| **Google Gemini** | Free tier | `GOOGLE_API_KEY` or `GEMINI_API_KEY` |
| **OpenRouter** | Pay-per-use | `OPENROUTER_API_KEY` |

### Setting API Keys

You can set API keys in two ways:

**Option 1: Configuration File (Recommended)**

Edit `analysis_config.cfg` in the project root:
```ini
[analysis]
provider: github
api_key: ghp_your_token_here
```

**Option 2: Environment Variables**

```bash
# Add to ~/.bashrc or ~/.zshrc
export GITHUB_TOKEN="ghp_your_token_here"
export OPENAI_API_KEY="sk-your-key-here"
```

Or set before running:
```bash
GITHUB_TOKEN=ghp_xxx python3 analyze_print.py --provider github
```

---

## Configuration File

All analysis settings can be configured in `analysis_config.cfg`:

```ini
[analysis]
# LLM provider: github, ollama, openai, anthropic, gemini, openrouter
provider: github

# API key (overrides environment variables)
api_key: 

# Model name (optional - uses provider default if blank)
model: 

# Auto-apply safe suggestions
auto_apply: false

# Show analysis in Klipper console
notify_console: true

# Moonraker URL
moonraker_url: http://localhost:7125

# Hook mode: poll or webhook
hook_mode: poll

# Webhook port
webhook_port: 7126

# Log directory
log_dir: ~/printer_data/logs/adaptive_flow

# Max log files to keep
max_log_files: 20

# Include klippy.log in analysis
analyze_klippy_log: true

# Max CSV rows to send to LLM
max_csv_rows: 100
```

---

## Usage

### Analyze Most Recent Print

```bash
python3 analyze_print.py
python3 analyze_print.py --provider github
python3 analyze_print.py --provider ollama   # Local, no API key
```

### Analyze Specific Print

```bash
python3 analyze_print.py ~/printer_data/logs/adaptive_flow/20231215_143022_benchy_summary.json
```

### Auto-Apply Safe Suggestions

```bash
python3 analyze_print.py --auto
```

Only applies changes marked `safe_to_auto_apply: true` by the LLM.

---

## What Gets Analyzed

The system analyzes:

1. **Print Session Summary** (`*_summary.json`)
   - Duration, material, temperatures
   - Average/max boost, PWM, flow
   - Thermal lag measurements

2. **Detailed CSV Data** (`*.csv`)
   - Per-second: temp, boost, flow, speed, PWM, PA, Z
   - Last 100 rows sampled for LLM context

3. **Klipper Log** (`klippy.log`)
   - Thermal warnings
   - Timer/MCU errors
   - Driver issues
   - Any `!!` error lines

---

## Example Output

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ADAPTIVE FLOW PRINT ANALYSIS                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Provider: GitHub Models (gpt-4o-mini)                 â•‘
â•‘ Print: benchy.gcode                                   â•‘
â•‘ Duration: 45.2 min                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

ğŸ“Š ASSESSMENT
Good thermal response. Heater kept up well with avg 68% PWM.
Minor improvements possible for high-speed sections.

âš ï¸ ISSUES FOUND
[medium] Speed boost may be insufficient at 250mm/s moves
[low] Slight thermal lag on rapid flow transitions

ğŸ’¡ SUGGESTIONS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parameter       â”‚ Current â”‚ Suggested â”‚ Reason                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ speed_boost_k   â”‚ 0.08    â”‚ 0.10      â”‚ Better heat at 250mm/s   â”‚
â”‚ ramp_rate_rise  â”‚ 4.0     â”‚ 5.0       â”‚ Faster response to flow  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ QUALITY PREDICTION: good

ğŸ’¾ Analysis saved to: ~/printer_data/logs/adaptive_flow/analysis_20231215_143022_benchy.json
```

---

## Auto-Analysis After Prints

Use `moonraker_hook.py` to automatically analyze every print.

### Option 1: Polling Mode (Simplest)

```bash
python3 moonraker_hook.py --provider github
```

Runs in foreground, polls Moonraker for print completion.

### Option 2: Systemd Service (Recommended)

1. Configure `analysis_config.cfg` with your API key and settings

2. Create `/etc/systemd/system/adaptive-flow-hook.service`:

```ini
[Unit]
Description=Adaptive Flow Print Analyzer Hook
After=moonraker.service
Requires=moonraker.service

[Service]
Type=simple
User=pi
WorkingDirectory=/home/pi/Klipper-Adaptive-Flow
ExecStart=/usr/bin/python3 /home/pi/Klipper-Adaptive-Flow/moonraker_hook.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

Note: All settings (provider, auto-apply, etc.) come from `analysis_config.cfg`.

3. Enable and start:
```bash
sudo systemctl daemon-reload
sudo systemctl enable adaptive-flow-hook
sudo systemctl start adaptive-flow-hook
```

Check status:
```bash
sudo systemctl status adaptive-flow-hook
journalctl -u adaptive-flow-hook -f
```

### Option 3: Webhook Mode

If you prefer webhooks over polling, add to `moonraker.conf`:

```ini
[notifier print_complete]
url: json://localhost:7126/server/custom/adaptive_flow_analyze
events: complete
body: {"filename": "{event_args[0].filename}", "status": "{event_args[0].state}"}
```

Then run:
```bash
python3 moonraker_hook.py --mode webhook --port 7126
```

---

## Moonraker Hook Options

```bash
python3 moonraker_hook.py --help
```

| Flag | Description |
|------|-------------|
| `--provider X` | LLM provider (github, ollama, openai, etc.) |
| `--mode poll` | Poll Moonraker for print state (default) |
| `--mode webhook` | Listen for Moonraker notifications |
| `--port N` | Port for webhook listener (default: 7126) |
| `--auto-apply` | Auto-apply safe suggestions |

---

## Analysis Results

Results are saved as JSON alongside print logs:

```
~/printer_data/logs/adaptive_flow/
â”œâ”€â”€ 20231215_143022_benchy.csv           # Raw data
â”œâ”€â”€ 20231215_143022_benchy_summary.json  # Print summary
â””â”€â”€ analysis_20231215_143022_benchy.json # LLM analysis
```

### Analysis JSON Format

```json
{
  "analyzed_at": "2023-12-15T15:30:22",
  "provider": "github",
  "model": "gpt-4o-mini",
  "source_file": "20231215_143022_benchy_summary.json",
  "analysis": {
    "assessment": "Good thermal response overall...",
    "issues": [
      {"severity": "medium", "description": "Speed boost insufficient at 250mm/s"}
    ],
    "suggestions": [
      {
        "parameter": "speed_boost_k",
        "current": "0.08",
        "suggested": "0.10",
        "reason": "Better heating for high-speed moves",
        "safe_to_auto_apply": true
      }
    ],
    "print_quality_prediction": "good",
    "klippy_concerns": "none",
    "notes": "Consider increasing ramp rate for faster flow transitions"
  }
}
```

---

## Tunable Parameters

The LLM can suggest changes to these `auto_flow.cfg` variables:

| Parameter | Description | Default |
|-----------|-------------|---------|
| `speed_boost_k` | Â°C per mm/s above 100mm/s | 0.08 |
| `speed_boost_threshold` | Speed to trigger boost | 100.0 |
| `ramp_rate_rise` | Heat-up rate (Â°C/s) | 4.0 |
| `ramp_rate_fall` | Cool-down rate (Â°C/s) | 1.0 |
| `max_boost_limit` | Maximum temp boost | 50.0 |
| `flow_smoothing` | Flow EMA factor | 0.15 |

Material-specific parameters in `material_profiles.cfg`:

| Parameter | Description |
|-----------|-------------|
| `flow_k` | Â°C per mmÂ³/s of flow |
| `max_boost` | Per-material boost cap |
| `pa_boost_k` | PA reduction per Â°C |
| `ramp_rise` / `ramp_fall` | Material ramp rates |

---

## Troubleshooting

### No logs found
Check that logging is working:
```bash
ls -la ~/printer_data/logs/adaptive_flow/
```

If empty, ensure `AT_LOG_START` is being called (happens automatically in `AT_START`).

### API key errors
```bash
# Test your key
echo $GITHUB_TOKEN
python3 -c "import os; print(os.environ.get('GITHUB_TOKEN', 'NOT SET'))"
```

### Ollama not responding
```bash
# Check Ollama is running
curl http://localhost:11434/api/tags

# Pull a model
ollama pull llama3.1
```

### Hook not detecting print completion
```bash
# Test Moonraker connection
curl http://localhost:7125/printer/objects/query?print_stats
```
